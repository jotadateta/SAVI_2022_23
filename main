#!/usr/bin/env python3
#
from textwrap import dedent
import cv2
import numpy as np
import math

def drawbox(img,bbox):
    x,y,w,h = int(bbox[0]),int(bbox[1]),int(bbox[2]),int(bbox[3])
    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)
    cv2.putText(img, "tracking", (75,50),cv2.FONT_HERSHEY_COMPLEX,0.7,(0,0,255),1)

def detection_faces():
    count = 0
    detection_counter = 0 
    previous_detections = []

    ####################FACE DETECTION#############################
    # Load the cascade
    face_cascade = cv2.CascadeClassifier('/home/jota/Documents/SAVI/savi_22-23/SAVI_Trabalho1/dataset/haarcascade_frontalface_default.xml')

    # To capture video from webcam. 
    cap = cv2.VideoCapture(0)
    # To use a video file as input 
    # cap = cv2.VideoCapture('filename.mp4')

    
    tracker = cv2.TrackerCSRT_create()
    _, img = cap.read()
    bbox = cv2.selectROI("tracking",img,False)
    tracker.init(img,bbox)
    #print(bbox)
    
    while True:
        # Read the frame
        _, img = cap.read()

        count = count + 1
        detections = []
        
        sucess, bbox = tracker.update(img)
        if sucess:
            drawbox(img,bbox)
        else:
            cv2.putText(img, "Lost", (75,50),cv2.FONT_HERSHEY_COMPLEX,0.7,(0,0,255),1)

        # Convert to grayscale
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # Detect the faces
        faces = face_cascade.detectMultiScale(gray, 1.1, 7)
        #print(faces)
        # Draw the rectangle around each face
        detections=[]
        for bbox in faces:  
            x1,y1,w,h = bbox
            cv2.rectangle(img, (x1, y1), (x1+w, y1+h), (255, 0, 0), 2)
            detection_counter = detection_counter + 1
            detections.append(bbox)
            #print (detection_counter)
            
            mask = np.zeros(img.shape[:2], dtype="uint8")
            cv2.rectangle(mask, (x1, y1), (x1+w, y1+h), 255, -1)
        
        for point_1 in detections:
            for point_2 in previous_detections:
                distance = abs(point_1[0] - point_2[0])

                if distance > 10:
                    print("nova pessoa")
            
        #print("fps "+ str(count) + " prev " + str(previous_detections) + " curr "+ str(detections))
        
        
        
        
        previous_detections = detections.copy()
        
        # Display
        cv2.imshow('img', img)
        
        
        
        # Stop if "Q" key is pressed
        if cv2.waitKey(0) == ord('q'):
            break
#########################################################################
    


if __name__ == "__main__":
    detection_faces()